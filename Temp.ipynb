
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from timm.models.vision_transformer import vit_base_patch16_224\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from torchvision.transforms import functional as F\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import wandb\n",
    "import timm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a random tensor of shape (2,100,100)\n",
    "x= torch.rand(2, 100, 100)\n",
    "x_i= torch.rand(2, 100, 100)\n",
    "x_j= torch.rand(2, 100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform= transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "#create a custom dataset and add one augmentation\n",
    "class CustomDataset():\n",
    "    def __init__(self,matrix,transform=None):\n",
    "        self.matrix=matrix\n",
    "        #transform the data\n",
    "        self.transform=transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.matrix)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        matrix= self.matrix[index]\n",
    "        if self.transform:\n",
    "            x_i= self.transform(matrix)\n",
    "            x_j= self.transform(matrix)\n",
    "\n",
    "        return matrix,x_i,x_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        self.head_dim = d_model // num_heads\n",
    "        assert self.head_dim * num_heads == d_model, \"d_model must be divisible by num_heads\"\n",
    "        self.qkv = nn.Linear(d_model, d_model * 3, bias=False)\n",
    "        self.fc_out = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_length, _ = x.size()\n",
    "        qkv = self.qkv(x).view(batch_size, seq_length, self.num_heads, 3 * self.head_dim)\n",
    "        qkv = qkv.permute(0, 2, 1, 3).contiguous().view(batch_size * self.num_heads, seq_length, 3 * self.head_dim)\n",
    "        queries, keys, values = qkv.chunk(3, dim=-1)\n",
    "        energy = torch.matmul(queries, keys.transpose(-2, -1)) / self.head_dim ** 0.5\n",
    "        attention = torch.softmax(energy, dim=-1)\n",
    "        out = torch.matmul(attention, values)\n",
    "        out = out.view(batch_size, self.num_heads, seq_length, self.head_dim)\n",
    "        out = out.permute(0, 2, 1, 3).contiguous().view(batch_size, seq_length, self.d_model)\n",
    "        out = self.fc_out(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create MLP model with 2 hidden layers\n",
    "class Network(nn.Module):\n",
    "    def __init__(self, input_size=100):\n",
    "        super(Network, self).__init__()\n",
    "        multi_head_self_attention = MultiHeadSelfAttention(d_model=100, num_heads=10)\n",
    "        self.fc1 = nn.Linear(100, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reconstructive_net(nn.Module):\n",
    "    def __init__(self, input_size=2):\n",
    "        super(Reconstructive_net, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 100)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Contrastive_net(nn.Module):\n",
    "    def __init__(self, input_size=2):\n",
    "        super(Contrastive_net, self).__init__()\n",
    "        self.fc1 = nn.Flatten()\n",
    "        self.fc2 = nn.Linear(200, 8)\n",
    "        self.norm1= nn.LayerNorm(8)\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.norm1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_model=Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrastive_model=Contrastive_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructive_model = Reconstructive_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_model=main_model.to(device)\n",
    "contrastive_model=contrastive_model.to(device)\n",
    "reconstructive_model=reconstructive_model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeding_i=main_model(x_i)\n",
    "# embeding_j=main_model(x_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_recon_i=reconstructive_model(embeding_i)\n",
    "# x_recon_j=reconstructive_model(embeding_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_contrast_i=contrastive_model(embeding_i)\n",
    "# x_contrast_j=contrastive_model(embeding_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimCLR_Loss(nn.Module):\n",
    "    def __init__(self, batch_size, temperature):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.temperature = temperature\n",
    "\n",
    "        self.mask = self.mask_correlated_samples(batch_size)\n",
    "        self.criterion = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "        self.similarity_f = nn.CosineSimilarity(dim=2)\n",
    "\n",
    "    def mask_correlated_samples(self, batch_size):\n",
    "        N = 2 * batch_size\n",
    "        mask = torch.ones((N, N), dtype=bool)\n",
    "        mask = mask.fill_diagonal_(0)\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            mask[i, batch_size + i] = 0\n",
    "            mask[batch_size + i, i] = 0\n",
    "        return mask\n",
    "\n",
    "    def forward(self, z_i, z_j):\n",
    "        N = 2 * self.batch_size\n",
    "        z = torch.cat((z_i, z_j), dim=0)\n",
    "        sim = self.similarity_f(z.unsqueeze(1), z.unsqueeze(0)) / self.temperature\n",
    "        # print(\"sim:\",sim.shape)\n",
    "        sim_i_j = torch.diag(sim, self.batch_size)\n",
    "        sim_j_i = torch.diag(sim, -self.batch_size)\n",
    "        # print(\"sim_i_j\")\n",
    "        # print(sim_i_j.shape)\n",
    "        # print(sim_j_i)\n",
    "        # print(\"sim_j_i\")\n",
    "        # print(sim_j_i.shape)\n",
    "        # print(sim_j_i)\n",
    "        # We have 2N samples, but with Distributed training every GPU gets N examples too, resulting in: 2xNxN\n",
    "        positive_samples = torch.cat((sim_i_j, sim_j_i), dim=0).reshape(N, 1)\n",
    "        negative_samples = sim[self.mask].reshape(N, -1)\n",
    "        #SIMCLR\n",
    "        labels = torch.from_numpy(np.array([0]*N)).reshape(-1).to(positive_samples.device).long() #.float()\n",
    "        logits = torch.cat((positive_samples, negative_samples), dim=1)\n",
    "        loss = self.criterion(logits, labels)\n",
    "        loss /= N\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrastive_loss=SimCLR_Loss(32, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_contrastive=contrastive_model(x_contrast_i, x_contrast_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=torch.rand(50,100,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=CustomDataset(data,transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader=DataLoader(dataset,batch_size=32,shuffle=True,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=optim.Adam(main_model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,10):\n",
    "    for x,x_i,x_j in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        x=x.to(device)\n",
    "        x_i=x_i.to(device)\n",
    "        x_j=x_j.to(device)\n",
    "        x=x.squeeze()\n",
    "        x_i=x_i.squeeze()\n",
    "        x_j=x_j.squeeze()\n",
    "        # print(x_i.shape)\n",
    "        # print(x_j.shape)\n",
    "        # print(\"=====\")\n",
    "        # print(\"main\")\n",
    "        embeding_i=main_model(x_i)\n",
    "        embeding_j=main_model(x_j)\n",
    "        # print(embeding_i.shape)\n",
    "        # print(embeding_j.shape)\n",
    "        # print(\"=====\")\n",
    "        # print(\"recon\")\n",
    "        x_recon_i=reconstructive_model(embeding_i)\n",
    "        x_recon_j=reconstructive_model(embeding_j)\n",
    "        # print(x_recon_i.shape)\n",
    "        # print(x_recon_j.shape)\n",
    "        # print(\"=====\")\n",
    "\n",
    "        # print(\"contrast\")\n",
    "        x_contrast_i=contrastive_model(embeding_i)\n",
    "        x_contrast_j=contrastive_model(embeding_j)\n",
    "        # print(x_contrast_i.shape)\n",
    "        # print(x_contrast_j.shape)\n",
    "        # print(\"=====\")\n",
    "        print(\"x\",x.shape)\n",
    "        loss_contrastive=contrastive_loss(x_contrast_i, x_contrast_j)\n",
    "        loss_reconstructive= criterion(x_recon_i,x)+criterion(x_recon_j,x)\n",
    "        loss=loss_contrastive+loss_reconstructive\n",
    "        loss.backward()\n",
    "\n",
    "        print(loss_contrastive,loss_reconstructive)\n",
    "        print(\"loss:\",loss)\n",
    "        optimizer.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_i_j=torch.rand(30)\n",
    "sim_j_i=torch.rand(30)\n",
    "N=60\n",
    "torch.cat((sim_i_j, sim_j_i), dim=0).reshape(60, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
